{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from iterdub import iterdub as ib\n",
    "from iterpop import iterpop as ip\n",
    "from keyname import keyname as kn\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from nbmetalog import nbmetalog as nbm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from slugify import slugify\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from teeplot import teeplot as tp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conduitpylib.utils import (\n",
    "    consolidate_merge,\n",
    "    count_outliers,\n",
    "    count_nonoutliers,\n",
    "    count_proportion_outliers,\n",
    ")\n",
    "\n",
    "from conduitpylib.viz import (\n",
    "    performance_semantics_plot,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbm.print_metadata()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inlet = pd.read_csv(\n",
    "    'https://osf.io/jgpnv/download',\n",
    "    compression='gzip',\n",
    ").dropna(\n",
    "    subset=['Process Instance UUID'],\n",
    ")\n",
    "nbm.print_dataframe_summary(*eval(nbm.nvp_expr(\n",
    "    'df_inlet'\n",
    ")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outlet = pd.read_csv(\n",
    "    'https://osf.io/ncdfq/download',\n",
    "    compression='gzip',\n",
    ").dropna(\n",
    "    subset=['Process Instance UUID'],\n",
    ")\n",
    "nbm.print_dataframe_summary(*eval(nbm.nvp_expr(\n",
    "    'df_outlet'\n",
    ")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = consolidate_merge(\n",
    "    df_inlet,\n",
    "    df_outlet,\n",
    "    on=['Process Instance UUID', 'Update'],\n",
    "    suffixes=(' Inlet', ' Outlet'),\n",
    "    how='outer',\n",
    ")\n",
    "if all(df_inlet['Runtime Seconds Elapsed'] == df_outlet['Runtime Seconds Elapsed']):\n",
    "    df['Runtime Seconds Elapsed Inlet'] = df['Runtime Seconds Elapsed']\n",
    "    df['Runtime Seconds Elapsed Outlet'] = df['Runtime Seconds Elapsed']\n",
    "nbm.print_dataframe_synopsis(*eval(nbm.nvp_expr(\n",
    "    'df'\n",
    ")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({\n",
    "    'Num Inlets' : 'int64',\n",
    "    'Num Outlets' : 'int64',\n",
    "    'Num Puts Attempted' : 'int64',\n",
    "    'Num Try Puts Attempted' : 'int64',\n",
    "    'Num Blocking Puts' : 'int64',\n",
    "    'Num Try Puts That Succeeded' : 'int64',\n",
    "    'Num Puts That Succeeded Eventually' : 'int64',\n",
    "    'Num Blocking Puts That Succeeded Immediately' : 'int64',\n",
    "    'Num Puts That Succeeded Immediately' : 'int64',\n",
    "    'Num Puts That Blocked' : 'int64',\n",
    "    'Num Dropped Puts' : 'int64',\n",
    "    'Num Round Trip Touches Inlet' : 'int64',\n",
    "    'Net Flux Through Duct' : 'int64',\n",
    "    'proc' : 'int64',\n",
    "    'Snapshot' : 'int64',\n",
    "    'Has Execution Blur' : 'bool',\n",
    "    'Replicate' : 'int64',\n",
    "    'Async Mode' : 'int64',\n",
    "    'Num Threads' : 'int64',\n",
    "    'Num Processes' : 'int64',\n",
    "    'SLURM_NNODES' : 'int64',\n",
    "    'SLURM_NTASKS' : 'int64',\n",
    "    'SLURM_CPUS_ON_NODE' : 'int64',\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hostname'] = df.apply(\n",
    "    lambda row: kn.unpack(row['Source File Inlet'])['_hostname'],\n",
    "    axis=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Num Nodes'] = df['SLURM_NNODES']\n",
    "df['Num Tasks'] = df['SLURM_NTASKS']\n",
    "df['Num Simels Per Cpu'] = df['Num Simulation Elements Per Cpu']\n",
    "df['Num Cpus'] = df['Num Threads'] * df['Num Processes']\n",
    "df['Allocated Tasks Per Node'] = df['Num Tasks'] // df['Num Nodes']\n",
    "df['Cpus Per Node'] = df['Allocated Tasks Per Node']\n",
    "df['Delivery Time Inlet'] = (df['Num Puts Attempted'] - 1) / df['Num Round Trip Touches Inlet']\n",
    "df['Delivery Time Outlet'] = (df['Num Pulls Attempted'] - 1) / df['Num Round Trip Touches Outlet']\n",
    "df['Intermittancy'] = df['Num Pulls That Were Laden Immediately'] / df[['Net Flux Through Duct', 'Num Pulls Attempted']].min(axis=1)\n",
    "df['Inlet-Seconds Elapsed'] = df['Num Inlets'] * df['Runtime Seconds Elapsed Inlet']\n",
    "df['Outlet-Seconds Elapsed'] = df['Num Outlets'] * df['Runtime Seconds Elapsed Outlet']\n",
    "df['Latency Simsteps Inlet'] = df['Delivery Time Inlet']\n",
    "df['Latency Simsteps Outlet'] = df['Delivery Time Inlet']\n",
    "df['Simstep Period Inlet (s)'] = df['Inlet-Seconds Elapsed'] / df['Num Puts Attempted']\n",
    "df['Simstep Period Outlet (s)'] =  df['Outlet-Seconds Elapsed'] / df['Num Pulls Attempted']\n",
    "df['Latency Walltime Inlet (s)'] = df['Latency Simsteps Inlet'] * df['Simstep Period Inlet (s)']\n",
    "df['Latency Walltime Outlet (s)'] = df['Latency Simsteps Outlet'] * df['Simstep Period Outlet (s)']\n",
    "df['Log Num Processes'] = np.log(df['Num Processes']) / np.log(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_distiller = lambda row: {k : v for k, v in row.items() if k in ('Num Nodes', 'Num Processes')}\n",
    "\n",
    "allocation_idx_mapper = {\n",
    "    val : idx\n",
    "    for idx, val\n",
    "    in enumerate(df['Allocation'].unique())\n",
    "}\n",
    "allocation_idx_mapped_title = ' | '.join(f'{idx} = {val}' for val, idx in allocation_idx_mapper.items())\n",
    "df[allocation_idx_mapped_title] = df.apply(\n",
    "    lambda row: allocation_idx_mapper[row['Allocation']],\n",
    "    axis=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep DataFrame Variants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/40629420\n",
    "df_finalized_observations = df.sort_values('Update', ascending=False).drop_duplicates(['Process Instance UUID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blurry_snapshots = df[\n",
    "    df['Has Execution Blur'].astype(bool)\n",
    "    & (df['Snapshot'] <= 5 )\n",
    "    # exclude excess, unintended snapshots from runs that took a while to shut down\n",
    "    # (i.e., from at the 6 minute mark and beyond)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_world_sum = df_finalized_observations.groupby([\n",
    "    'Replicate',\n",
    "    'Async Mode',\n",
    "    'Num Processes',\n",
    "    'Num Nodes',\n",
    "    'Num Simels Per Cpu',\n",
    "    'Allocated Tasks Per Node',\n",
    "    'Cpus Per Node',\n",
    "    'Allocation',\n",
    "    allocation_idx_mapped_title,\n",
    "],  as_index=False).sum()\n",
    "\n",
    "df_world_sum['Fraction Messages Utilized'] = df_world_sum['Num Reads That Were Fresh'] / df_world_sum['Num Try Puts Attempted']\n",
    "df_world_sum['Fraction Messages Delivered'] = df_world_sum['Num Try Puts That Succeeded'] / df_world_sum['Num Try Puts Attempted']\n",
    "df_world_sum['Delivery Failure Rate'] = 1.0 - df_world_sum['Fraction Messages Delivered']\n",
    "df_world_sum['Fraction Messages Dropped'] = df_world_sum['Delivery Failure Rate']\n",
    "df_world_sum['Fraction Try Pulls That Were Laden'] = df_world_sum['Num Try Pulls That Were Laden'] / df_world_sum['Num Try Pulls Attempted']\n",
    "df_world_sum['Round Trip Touches Per Attempted Pull'] = df_world_sum['Num Round Trip Touches Outlet'] / df_world_sum['Num Try Pulls Attempted']\n",
    "df_world_sum['Round Trip Touches Per Attempted Put'] = df_world_sum['Num Round Trip Touches Inlet'] / df_world_sum['Num Try Puts Attempted']\n",
    "df_world_sum['Num Inflight Messages'] = 2.0 / df_world_sum['Round Trip Touches Per Attempted Put'] - 1\n",
    "df_world_sum['Fraction Duct Flux Stepped Through'] = df_world_sum['Num Revisions Pulled'] / df_world_sum['Net Flux Through Duct']\n",
    "df_world_sum['Fraction Duct Flux Jumped Over'] = 1.0 - df_world_sum['Fraction Duct Flux Stepped Through']\n",
    "df_world_sum['Round Trip Touches Per Runtime Second'] = df_world_sum['Num Round Trip Touches Inlet'] / df_world_sum['Runtime Seconds Elapsed Inlet']\n",
    "df_world_sum['Latency Simsteps Inlet'] = (df_world_sum['Num Puts Attempted'] - 1) / df_world_sum['Num Round Trip Touches Inlet']\n",
    "df_world_sum['Latency Simsteps Outlet'] = (df_world_sum['Num Pulls Attempted'] - 1) / df_world_sum['Num Round Trip Touches Outlet']\n",
    "df_world_sum['Delivery Clumpiness'] = 1.0 - df_world_sum['Num Pulls That Were Laden Immediately'] / df_world_sum[['Net Flux Through Duct', 'Num Pulls Attempted']].min(axis=1)\n",
    "df_world_sum['Intermittancy'] = df_world_sum['Delivery Clumpiness']\n",
    "df_world_sum['Simstep Period Inlet (s)'] = df_world_sum['Inlet-Seconds Elapsed'] / df_world_sum['Num Puts Attempted']\n",
    "df_world_sum['Simstep Period Outlet (s)'] = df_world_sum['Outlet-Seconds Elapsed'] / df_world_sum['Num Pulls Attempted']\n",
    "df_world_sum['Latency Walltime Inlet (s)'] = df_world_sum['Latency Simsteps Inlet'] * df_world_sum['Simstep Period Inlet (s)']\n",
    "df_world_sum['Latency Walltime Outlet (s)'] = df_world_sum['Latency Simsteps Outlet'] * df_world_sum['Simstep Period Outlet (s)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs = df_blurry_snapshots.groupby(\n",
    "    [\n",
    "        'Process Instance UUID',\n",
    "        'Snapshot',\n",
    "        # subsequent items aren't meaningful to groupby\n",
    "        # but are just included so they pass through untouched\n",
    "        'Async Mode',\n",
    "        'Num Nodes',\n",
    "        'Allocated Tasks Per Node',\n",
    "        'Cpus Per Node',\n",
    "        'Num Processes',\n",
    "        'Log Num Processes',\n",
    "        'Num Simels Per Cpu',\n",
    "        'Replicate',\n",
    "        'proc',\n",
    "        'Hostname',\n",
    "        'Num Inlets',\n",
    "        'Num Outlets',\n",
    "        'Execution Instance UUID',\n",
    "        'Num Threads',\n",
    "        'Allocation',\n",
    "        allocation_idx_mapped_title,\n",
    "\n",
    "    ],\n",
    "    as_index=False,\n",
    ").aggregate({\n",
    "    'Num Puts Attempted' : np.ptp,\n",
    "    'Num Try Puts Attempted' : np.ptp,\n",
    "    'Num Blocking Puts'  : np.ptp,\n",
    "    'Num Try Puts That Succeeded' : np.ptp,\n",
    "    'Num Puts That Succeeded Eventually' : np.ptp,\n",
    "    'Num Blocking Puts That Succeeded Immediately' : np.ptp,\n",
    "    'Num Puts That Succeeded Immediately' : np.ptp,\n",
    "    'Num Puts That Blocked' : np.ptp,\n",
    "    'Num Dropped Puts' : np.ptp,\n",
    "    'Num Reads Performed' : np.ptp,\n",
    "    'Num Reads That Were Fresh' : np.ptp,\n",
    "    'Num Reads That Were Stale' : np.ptp,\n",
    "    'Num Revisions Pulled' : np.ptp,\n",
    "    'Num Try Pulls Attempted' : np.ptp,\n",
    "    'Num Blocking Pulls' : np.ptp,\n",
    "    'Num Blocking Pulls That Blocked' : np.ptp,\n",
    "    'Num Revisions From Try Pulls' : np.ptp,\n",
    "    'Num Revisions From Blocking Pulls' : np.ptp,\n",
    "    'Num Pulls Attempted' : np.ptp,\n",
    "    'Num Pulls That Were Laden Eventually' : np.ptp,\n",
    "    'Num Blocking Pulls That Were Laden Immediately' : np.ptp,\n",
    "    'Num Blocking Pulls That Were Laden Eventually' : np.ptp,\n",
    "    'Num Pulls That Were Laden Immediately' : np.ptp,\n",
    "    'Num Try Pulls That Were Laden' : np.ptp,\n",
    "    'Num Try Pulls That Were Unladen' : np.ptp,\n",
    "    'Net Flux Through Duct' : np.ptp,\n",
    "    'Num Round Trip Touches Inlet' : np.ptp,\n",
    "    'Num Round Trip Touches Outlet' : np.ptp,\n",
    "# why are these missing?\n",
    "#     'Row Initial Timepoint (ns) Inlet' : np.ptp,\n",
    "#     'Row Initial Timepoint (ns) Outlet' : np.ptp,\n",
    "    'Row Final Timepoint (ns) Inlet' : np.ptp,\n",
    "    'Row Final Timepoint (ns) Outlet' : np.ptp,\n",
    "    'Runtime Seconds Elapsed Inlet' : np.mean,\n",
    "    'Runtime Seconds Elapsed Outlet' : np.mean,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs['Fraction Messages Delivered'] = (\n",
    "    df_snapshot_diffs['Num Try Puts That Succeeded']\n",
    "    / df_snapshot_diffs['Num Try Puts Attempted']\n",
    ")\n",
    "df_snapshot_diffs['Delivery Success Rate'] = (\n",
    "    df_snapshot_diffs['Num Try Puts That Succeeded']\n",
    "    / df_snapshot_diffs['Num Try Puts Attempted']\n",
    ")\n",
    "df_snapshot_diffs['Delivery Failure Rate'] = 1 - df_snapshot_diffs['Delivery Success Rate']\n",
    "df_snapshot_diffs['Fraction Messages Dropped'] = df_snapshot_diffs['Delivery Failure Rate']\n",
    "df_snapshot_diffs['Fraction Try Pulls That Were Laden'] = (\n",
    "    df_snapshot_diffs['Num Try Pulls That Were Laden']\n",
    "    / df_snapshot_diffs['Num Try Pulls Attempted']\n",
    ")\n",
    "\n",
    "df_snapshot_diffs['Round Trip Touches Per Attempted Put'] = (\n",
    "    df_snapshot_diffs['Num Round Trip Touches Inlet']\n",
    ") / df_snapshot_diffs['Num Try Puts Attempted']\n",
    "\n",
    "df_snapshot_diffs['Round Trip Touches Per Attempted Pull'] = (\n",
    "    df_snapshot_diffs['Num Round Trip Touches Outlet']\n",
    ") / df_snapshot_diffs['Num Try Pulls Attempted']\n",
    "\n",
    "df_snapshot_diffs['Round Trip Touches Per Runtime Nanosecond'] = (\n",
    "    df_snapshot_diffs['Num Round Trip Touches Outlet']\n",
    ") / df_snapshot_diffs['Row Final Timepoint (ns) Outlet']\n",
    "\n",
    "df_snapshot_diffs['Latency Simsteps Inlet'] = df_snapshot_diffs['Num Puts Attempted'] / df_snapshot_diffs['Num Round Trip Touches Inlet']\n",
    "df_snapshot_diffs['Latency Simsteps Outlet'] = df_snapshot_diffs['Num Pulls Attempted'] / df_snapshot_diffs['Num Round Trip Touches Outlet']\n",
    "df_snapshot_diffs['Delivery Clumpiness'] = 1.0 - df_snapshot_diffs['Num Pulls That Were Laden Immediately'] / df_snapshot_diffs[['Net Flux Through Duct', 'Num Pulls Attempted']].min(axis=1)\n",
    "df_snapshot_diffs['Intermittancy'] = df_snapshot_diffs['Delivery Clumpiness']\n",
    "df_snapshot_diffs['Inlet-Nanoseconds Elapsed'] = df_snapshot_diffs['Num Inlets'] * df_snapshot_diffs['Row Final Timepoint (ns) Inlet']\n",
    "df_snapshot_diffs['Outlet-Nanoseconds Elapsed'] = df_snapshot_diffs['Num Outlets'] * df_snapshot_diffs['Row Final Timepoint (ns) Outlet']\n",
    "df_snapshot_diffs['Simsteps Elapsed Inlet'] = df_snapshot_diffs['Num Puts Attempted'] / df_snapshot_diffs['Num Inlets']\n",
    "df_snapshot_diffs['Simsteps Elapsed Outlet'] = df_snapshot_diffs['Num Pulls Attempted'] / df_snapshot_diffs['Num Outlets']\n",
    "df_snapshot_diffs['Simstep Period Inlet (ns)'] = df_snapshot_diffs['Inlet-Nanoseconds Elapsed'] / df_snapshot_diffs['Num Puts Attempted']\n",
    "df_snapshot_diffs['Simstep Period Outlet (ns)'] = df_snapshot_diffs['Outlet-Nanoseconds Elapsed'] / df_snapshot_diffs['Num Pulls Attempted']\n",
    "df_snapshot_diffs['Latency Walltime Inlet (ns)'] = df_snapshot_diffs['Latency Simsteps Inlet'] * df_snapshot_diffs['Simstep Period Inlet (ns)']\n",
    "df_snapshot_diffs['Latency Walltime Outlet (ns)'] = df_snapshot_diffs['Latency Simsteps Outlet'] * df_snapshot_diffs['Simstep Period Outlet (ns)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs = df_snapshot_diffs.astype({\n",
    "    'Num Inlets' : 'int64',\n",
    "    'Num Outlets' : 'int64',\n",
    "    'proc' : 'int64',\n",
    "    'Snapshot' : 'int64',\n",
    "    'Replicate' : 'int64',\n",
    "    'Async Mode' : 'int64',\n",
    "    'Num Threads' : 'int64',\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Nodes' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-state Data Analysis\n",
    "\n",
    "This data appears to be skewed by ragged network launch/completion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facet_boxplot(*, data, col=None, row=None, x, y, showfliers=False):\n",
    "    g = sns.FacetGrid(\n",
    "        data,\n",
    "        col=col if col is not None and data[col].nunique() > 1 else None,\n",
    "        row=row if row is not None and data[row].nunique() > 1 else None,\n",
    "        margin_titles=True,\n",
    "        sharey='row',\n",
    "    )\n",
    "    g.map_dataframe(\n",
    "        sns.boxplot,\n",
    "        x,\n",
    "        y,\n",
    "        showfliers=showfliers,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency Walltime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    facet_boxplot,\n",
    "    data=df_world_sum,\n",
    "    row='Num Simels Per Cpu',\n",
    "    x=allocation_idx_mapped_title,\n",
    "    y='Latency Walltime Inlet (s)',\n",
    "    showfliers=True,\n",
    "    teeplot_outattrs={\n",
    "        **{\n",
    "            'transform' : 'endstate_sumedbyrep',\n",
    "        },\n",
    "        **nbm.collate_outattr_metadata(),\n",
    "    },\n",
    "    teeplot_subdir='latency-walltime-inlet-s',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    facet_boxplot,\n",
    "    data=df_world_sum,\n",
    "    row='Num Simels Per Cpu',\n",
    "    x=allocation_idx_mapped_title,\n",
    "    y='Latency Walltime Outlet (s)',\n",
    "    showfliers=True,\n",
    "    teeplot_outattrs={\n",
    "        **{\n",
    "            'transform' : 'endstate_sumedbyrep',\n",
    "        },\n",
    "        **nbm.collate_outattr_metadata(),\n",
    "    },\n",
    "    teeplot_subdir='latency-walltime-outlet-s',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency Simsteps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    facet_boxplot,\n",
    "    data=df_world_sum,\n",
    "    row='Num Simels Per Cpu',\n",
    "    x=allocation_idx_mapped_title,\n",
    "    y='Latency Simsteps Inlet',\n",
    "    showfliers=True,\n",
    "    teeplot_outattrs={\n",
    "        **{\n",
    "            'transform' : 'endstate_sumedbyrep',\n",
    "        },\n",
    "        **nbm.collate_outattr_metadata(),\n",
    "    },\n",
    "    teeplot_subdir='latency-simsteps-inlet',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    facet_boxplot,\n",
    "    data=df_world_sum,\n",
    "    row='Num Simels Per Cpu',\n",
    "    x=allocation_idx_mapped_title,\n",
    "    y='Latency Simsteps Outlet',\n",
    "    showfliers=True,\n",
    "    teeplot_outattrs={\n",
    "        **{\n",
    "            'transform' : 'endstate_sumedbyrep',\n",
    "        },\n",
    "        **nbm.collate_outattr_metadata(),\n",
    "    },\n",
    "    teeplot_subdir='latency-simsteps-outlet',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delivery Failure Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    facet_boxplot,\n",
    "    data=df_world_sum,\n",
    "\n",
    "    row='Num Simels Per Cpu',\n",
    "    x=allocation_idx_mapped_title,\n",
    "    y='Delivery Failure Rate',\n",
    "    showfliers=True,\n",
    "    teeplot_outattrs={\n",
    "        **{\n",
    "            'transform' : 'endstate_sumedbyrep',\n",
    "        },\n",
    "        **nbm.collate_outattr_metadata(),\n",
    "    },\n",
    "    teeplot_subdir='delivery-failure-rate',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delivery Clumpiness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    facet_boxplot,\n",
    "    data=df_world_sum,\n",
    "    row='Num Simels Per Cpu',\n",
    "    x=allocation_idx_mapped_title,\n",
    "    y='Delivery Clumpiness',\n",
    "    showfliers=True,\n",
    "    teeplot_outattrs={\n",
    "        **{\n",
    "            'transform' : 'endstate_sumedbyrep',\n",
    "        },\n",
    "        **nbm.collate_outattr_metadata(),\n",
    "    },\n",
    "    teeplot_subdir='delivery-clumpiness',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simstep Period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    facet_boxplot,\n",
    "    data=df_world_sum,\n",
    "    row='Num Simels Per Cpu',\n",
    "    x=allocation_idx_mapped_title,\n",
    "    y='Simstep Period Inlet (s)',\n",
    "    showfliers=True,\n",
    "    teeplot_outattrs={\n",
    "        **{\n",
    "            'transform' : 'endstate_sumedbyrep',\n",
    "        },\n",
    "        **nbm.collate_outattr_metadata(),\n",
    "    },\n",
    "    teeplot_subdir='simstep-period-inlet-s',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    facet_boxplot,\n",
    "    data=df_world_sum,\n",
    "    row='Num Simels Per Cpu',\n",
    "    x=allocation_idx_mapped_title,\n",
    "    y='Simstep Period Outlet (s)',\n",
    "    showfliers=True,\n",
    "    teeplot_outattrs={\n",
    "        **{\n",
    "            'transform' : 'endstate_sumedbyrep',\n",
    "        },\n",
    "        **nbm.collate_outattr_metadata(),\n",
    "    },\n",
    "    teeplot_subdir='simstep-period-outlet-s',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Snapshot Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facet_barplot(*, data, col=None, row=None, x, y, hue=None):\n",
    "    g = sns.FacetGrid(\n",
    "        data,\n",
    "        col=col if col is not None and data[col].nunique() > 1 else None,\n",
    "        row=row if row is not None and data[row].nunique() > 1 else None,\n",
    "        margin_titles=True,\n",
    "        sharey='row',\n",
    "    )\n",
    "    g.map_dataframe(\n",
    "        sns.barplot,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        hue=hue,\n",
    "    )\n",
    "\n",
    "    # adapted from https://stackoverflow.com/a/48208266\n",
    "    g.set_axis_labels(x_var=x, y_var=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facet_boxplot_withfliers(*, data, col=None, row=None, x, y, hue=None):\n",
    "    g = sns.FacetGrid(\n",
    "        data,\n",
    "        col=col if col is not None and data[col].nunique() > 1 else None,\n",
    "        row=row if row is not None and data[row].nunique() > 1 else None,\n",
    "        margin_titles=True,\n",
    "        sharey='row',\n",
    "    )\n",
    "    g.map_dataframe(\n",
    "        sns.boxplot,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        hue=hue,\n",
    "        showfliers=True,\n",
    "    )\n",
    "\n",
    "    # adapted from https://stackoverflow.com/a/48208266\n",
    "    g.set_axis_labels(x_var=x, y_var=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facet_boxplot_nofliers(*, data, col=None, row=None, x, y, hue=None):\n",
    "    g = sns.FacetGrid(\n",
    "        data,\n",
    "        col=col if col is not None and data[col].nunique() > 1 else None,\n",
    "        row=row if row is not None and data[row].nunique() > 1 else None,\n",
    "        margin_titles=True,\n",
    "        sharey='row',\n",
    "    )\n",
    "    g.map_dataframe(\n",
    "        sns.boxplot,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        hue=hue,\n",
    "        showfliers=False,\n",
    "    )\n",
    "\n",
    "    # adapted from https://stackoverflow.com/a/48208266\n",
    "    g.set_axis_labels(x_var=x, y_var=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency Walltime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for viz in facet_barplot, facet_boxplot_withfliers, facet_boxplot_nofliers:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=df_snapshot_diffs,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Latency Walltime Inlet (ns)',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='latency-walltime-inlet-ns',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Mean and Median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/a/13592901\n",
    "df_snapshot_diffs.groupby([\n",
    "    allocation_idx_mapped_title,\n",
    "]).agg({\n",
    "    'Latency Walltime Inlet (ns)' : [\n",
    "        np.mean,\n",
    "        np.median,\n",
    "    ],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median of Replicate Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_medians = df_snapshot_diffs.groupby([allocation_idx_mapped_title, 'Replicate']).agg({\n",
    "    'Latency Walltime Inlet (ns)': np.mean\n",
    "}).reset_index()\n",
    "\n",
    "median_of_medians = group_medians.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Latency Walltime Inlet (ns)': np.mean\n",
    "})\n",
    "\n",
    "baseline = median_of_medians.loc[1, \"Latency Walltime Inlet (ns)\"].squeeze()\n",
    "median_of_medians[\"normed delta\"] = (median_of_medians[\"Latency Walltime Inlet (ns)\"] - baseline) / baseline * 100\n",
    "median_of_medians\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median of Replicate Medians\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_medians = df_snapshot_diffs.groupby([allocation_idx_mapped_title, 'Replicate']).agg({\n",
    "    'Latency Walltime Inlet (ns)': np.median\n",
    "}).reset_index()\n",
    "\n",
    "median_of_medians = group_medians.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Latency Walltime Inlet (ns)': np.median\n",
    "})\n",
    "\n",
    "baseline = median_of_medians.loc[1, \"Latency Walltime Inlet (ns)\"].squeeze()\n",
    "median_of_medians[\"normed delta\"] = (median_of_medians[\"Latency Walltime Inlet (ns)\"] - baseline) / baseline * 100\n",
    "median_of_medians\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Absolute Deviance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf = df_snapshot_diffs.copy()\n",
    "xdf['median'] = xdf['Latency Walltime Inlet (ns)']\n",
    "xdf['median_abs_deviation'] = xdf['Latency Walltime Inlet (ns)']\n",
    "xdf = xdf.groupby([allocation_idx_mapped_title, 'Replicate']).agg({\n",
    "    'median': np.median,\n",
    "    'median_abs_deviation': stats.median_abs_deviation,\n",
    "}).reset_index()\n",
    "xdf[\"normed median_abs_deviation\"] = xdf[\"median_abs_deviation\"] / xdf[\"median\"] * 100\n",
    "\n",
    "name1, name2 = xdf[allocation_idx_mapped_title].unique()\n",
    "\n",
    "# Extract medians for each group\n",
    "group1 = xdf[xdf[allocation_idx_mapped_title] == name1]['normed median_abs_deviation']\n",
    "group2 = xdf[xdf[allocation_idx_mapped_title] == name2]['normed median_abs_deviation']\n",
    "\n",
    "print(len(group1), len(group2))\n",
    "stats.mannwhitneyu(group1, group2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(data=xdf, x=\"normed median_abs_deviation\", hue=allocation_idx_mapped_title)\n",
    "\n",
    "xdf.groupby(allocation_idx_mapped_title)['normed median_abs_deviation'].median().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonoutlier_counts = df_snapshot_diffs.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Latency Walltime Inlet (ns)': count_nonoutliers,\n",
    "}).reset_index()\n",
    "nonoutlier_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_counts = df_snapshot_diffs.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Latency Walltime Inlet (ns)': count_outliers,\n",
    "}).reset_index()\n",
    "outlier_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chi2_contingency(\n",
    "    np.vstack(\n",
    "        [\n",
    "            outlier_counts[\"Latency Walltime Inlet (ns)\"],\n",
    "            nonoutlier_counts[\"Latency Walltime Inlet (ns)\"],\n",
    "        ],\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Latency Walltime Inlet (ns)': lambda x: count_proportion_outliers(x) * 100,\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for viz in facet_barplot, facet_boxplot_withfliers, facet_boxplot_nofliers:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=df_snapshot_diffs,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Latency Walltime Outlet (ns)',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='latency-walltime-outlet-ns',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/a/13592901\n",
    "df_snapshot_diffs.groupby([\n",
    "    allocation_idx_mapped_title,\n",
    "]).agg({\n",
    "    'Latency Walltime Outlet (ns)' : [\n",
    "        np.mean,\n",
    "        np.median,\n",
    "    ],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency Simsteps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for viz in facet_barplot, facet_boxplot_withfliers, facet_boxplot_nofliers:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=df_snapshot_diffs,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Latency Simsteps Inlet',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='latency-simsteps-inlet',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdb3f6f-4c83-4804-a1e7-b773554af98d",
   "metadata": {},
   "source": [
    "### Simple Mean and Median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d5be0f-86c7-4104-b318-55caaba2f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/a/13592901\n",
    "df_snapshot_diffs.groupby([\n",
    "    allocation_idx_mapped_title,\n",
    "]).agg({\n",
    "    'Latency Simsteps Inlet' : [\n",
    "        np.mean,\n",
    "        np.median,\n",
    "    ],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5d8c3-5acb-456a-b0b3-d944248f6809",
   "metadata": {},
   "source": [
    "### Median of Replicate Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa1a75-b008-4d25-ae26-cd018aee0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_medians = df_snapshot_diffs.groupby([allocation_idx_mapped_title, 'Replicate']).agg({\n",
    "    'Latency Simsteps Inlet': np.mean\n",
    "}).reset_index()\n",
    "\n",
    "median_of_medians = group_medians.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Latency Simsteps Inlet': np.mean\n",
    "})\n",
    "\n",
    "baseline = median_of_medians.loc[1, \"Latency Simsteps Inlet\"].squeeze()\n",
    "median_of_medians[\"normed delta\"] = (median_of_medians[\"Latency Simsteps Inlet\"] - baseline) / baseline * 100\n",
    "median_of_medians\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d666eb-4ea7-4112-ab4c-fd05c992ad03",
   "metadata": {},
   "source": [
    "### Median of Replicate Medians\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02351780-005a-496c-bde5-49a0400f6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_medians = df_snapshot_diffs.groupby([allocation_idx_mapped_title, 'Replicate']).agg({\n",
    "    'Latency Simsteps Inlet': np.median\n",
    "}).reset_index()\n",
    "\n",
    "median_of_medians = group_medians.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Latency Simsteps Inlet': np.median\n",
    "})\n",
    "\n",
    "baseline = median_of_medians.loc[1, \"Latency Simsteps Inlet\"].squeeze()\n",
    "median_of_medians[\"normed delta\"] = (median_of_medians[\"Latency Simsteps Inlet\"] - baseline) / baseline * 100\n",
    "median_of_medians\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6467fb06-d857-40b3-bdc4-2858ba94a2df",
   "metadata": {},
   "source": [
    "### Median Absolute Deviance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d782ed5-420a-48f4-bb57-d4e8ee8e530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf = df_snapshot_diffs.copy()\n",
    "xdf['median'] = xdf['Latency Simsteps Inlet']\n",
    "xdf['median_abs_deviation'] = xdf['Latency Simsteps Inlet']\n",
    "xdf = xdf.groupby([allocation_idx_mapped_title, 'Replicate']).agg({\n",
    "    'median': np.median,\n",
    "    'median_abs_deviation': stats.median_abs_deviation,\n",
    "}).reset_index()\n",
    "xdf[\"normed median_abs_deviation\"] = xdf[\"median_abs_deviation\"] / xdf[\"median\"] * 100\n",
    "\n",
    "name1, name2 = xdf[allocation_idx_mapped_title].unique()\n",
    "\n",
    "# Extract medians for each group\n",
    "group1 = xdf[xdf[allocation_idx_mapped_title] == name1]['normed median_abs_deviation']\n",
    "group2 = xdf[xdf[allocation_idx_mapped_title] == name2]['normed median_abs_deviation']\n",
    "\n",
    "print(len(group1), len(group2))\n",
    "stats.mannwhitneyu(group1, group2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd12be-ab9f-4c97-8d96-8c12836460c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(data=xdf, x=\"normed median_abs_deviation\", hue=allocation_idx_mapped_title)\n",
    "\n",
    "xdf.groupby(allocation_idx_mapped_title)['normed median_abs_deviation'].median().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e4cf7-6589-4243-8140-29165c4be39d",
   "metadata": {},
   "source": [
    "### Percent Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4413cca-12b7-4552-9b91-cbf5aada8446",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonoutlier_counts = df_snapshot_diffs.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Latency Simsteps Inlet': count_nonoutliers,\n",
    "}).reset_index()\n",
    "nonoutlier_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49edb75-c9eb-4a92-981f-ce75b86516c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_counts = df_snapshot_diffs.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Latency Simsteps Inlet': count_outliers,\n",
    "}).reset_index()\n",
    "outlier_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f606740-6046-44ab-a421-9278c719bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chi2_contingency(\n",
    "    np.vstack(\n",
    "        [\n",
    "            outlier_counts[\"Latency Simsteps Inlet\"],\n",
    "            nonoutlier_counts[\"Latency Simsteps Inlet\"],\n",
    "        ],\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14469ba8-9d0e-482e-b309-18dbca4a2201",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Latency Simsteps Inlet': lambda x: count_proportion_outliers(x) * 100,\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for viz in facet_barplot, facet_boxplot_withfliers, facet_boxplot_nofliers:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=df_snapshot_diffs,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Latency Simsteps Outlet',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='latency-simsteps-outlet',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/a/13592901\n",
    "df_snapshot_diffs.groupby([\n",
    "    allocation_idx_mapped_title,\n",
    "]).agg({\n",
    "    'Latency Simsteps Outlet' : [\n",
    "        np.mean,\n",
    "        np.median,\n",
    "    ],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delivery Failure Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for viz in facet_barplot, facet_boxplot_withfliers, facet_boxplot_nofliers:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=df_snapshot_diffs,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Delivery Failure Rate',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='delivery-failure-rate',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583d05ae-9ff3-457b-a9dd-0d6c787f7142",
   "metadata": {},
   "source": [
    "### Simple Mean and Median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d7985-4a3d-4038-a108-8707eed6a1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/a/13592901\n",
    "df_snapshot_diffs.groupby([\n",
    "    allocation_idx_mapped_title,\n",
    "]).agg({\n",
    "    'Delivery Failure Rate' : [\n",
    "        np.mean,\n",
    "        np.median,\n",
    "    ],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afae0790-82f6-401e-af06-d59938cd7b44",
   "metadata": {},
   "source": [
    "### Median of Replicate Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbccb85-e96a-4dfc-8cd9-14205c572e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_medians = df_snapshot_diffs.groupby([allocation_idx_mapped_title, 'Replicate']).agg({\n",
    "    'Delivery Failure Rate': np.mean\n",
    "}).reset_index()\n",
    "\n",
    "median_of_medians = group_medians.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Delivery Failure Rate': np.mean\n",
    "})\n",
    "\n",
    "baseline = median_of_medians.loc[1, \"Delivery Failure Rate\"].squeeze()\n",
    "median_of_medians[\"normed delta\"] = (median_of_medians[\"Delivery Failure Rate\"] - baseline) / baseline * 100\n",
    "median_of_medians\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c19ee-ec1c-4b99-9342-8ab53dfc54a0",
   "metadata": {},
   "source": [
    "### Median of Replicate Medians\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68664a4a-5cfa-492e-a736-913d4aade9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_medians = df_snapshot_diffs.groupby([allocation_idx_mapped_title, 'Replicate']).agg({\n",
    "    'Delivery Failure Rate': np.median\n",
    "}).reset_index()\n",
    "\n",
    "median_of_medians = group_medians.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Delivery Failure Rate': np.median\n",
    "})\n",
    "\n",
    "baseline = median_of_medians.loc[1, \"Delivery Failure Rate\"].squeeze()\n",
    "median_of_medians[\"normed delta\"] = (median_of_medians[\"Delivery Failure Rate\"] - baseline) / baseline * 100\n",
    "median_of_medians\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbc9ca0-2b86-4d78-93f7-6b82a1501aae",
   "metadata": {},
   "source": [
    "### Median Absolute Deviance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f4ac8-c220-4cea-863b-bd787361236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf = df_snapshot_diffs.copy()\n",
    "xdf['median'] = xdf['Delivery Failure Rate']\n",
    "xdf['median_abs_deviation'] = xdf['Delivery Failure Rate']\n",
    "xdf = xdf.groupby([allocation_idx_mapped_title, 'Replicate']).agg({\n",
    "    'median': np.median,\n",
    "    'median_abs_deviation': stats.median_abs_deviation,\n",
    "}).reset_index()\n",
    "xdf[\"normed median_abs_deviation\"] = xdf[\"median_abs_deviation\"] / xdf[\"median\"] * 100\n",
    "\n",
    "name1, name2 = xdf[allocation_idx_mapped_title].unique()\n",
    "\n",
    "# Extract medians for each group\n",
    "group1 = xdf[xdf[allocation_idx_mapped_title] == name1]['normed median_abs_deviation']\n",
    "group2 = xdf[xdf[allocation_idx_mapped_title] == name2]['normed median_abs_deviation']\n",
    "\n",
    "try:\n",
    "    print(len(group1), len(group2))\n",
    "    print(group1.isna().all(), group2.isna().all())\n",
    "    res = stats.mannwhitneyu(group1, group2)\n",
    "    display(res)\n",
    "except Exception as e:\n",
    "    warnings.warn(f\"{type(e).__name__}: {e}\", RuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fbf214-a609-46fa-a98c-541714ed88bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ax = sns.histplot(data=xdf, x=\"normed median_abs_deviation\", hue=allocation_idx_mapped_title)\n",
    "except Exception as e:\n",
    "    warnings.warn(f\"{type(e).__name__}: {e}\", RuntimeWarning)\n",
    "\n",
    "try:\n",
    "    xdf.groupby(allocation_idx_mapped_title)['normed median_abs_deviation'].median().reset_index()\n",
    "except Exception as e:\n",
    "    warnings.warn(f\"{type(e).__name__}: {e}\", RuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e88ca0-24c6-4e4e-a336-7820e326c681",
   "metadata": {},
   "source": [
    "### Percent Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e193a7ab-b264-43b4-bec0-85dc1647f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonoutlier_counts = df_snapshot_diffs.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Delivery Failure Rate': count_nonoutliers,\n",
    "}).reset_index()\n",
    "nonoutlier_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8cf0f-ba65-4291-b9d6-90abd0ec3e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_counts = df_snapshot_diffs.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Delivery Failure Rate': count_outliers,\n",
    "}).reset_index()\n",
    "outlier_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af1ced2-08e5-4a4c-94f2-3cd9ccc15241",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chi2_contingency(\n",
    "    np.vstack(\n",
    "        [\n",
    "            outlier_counts[\"Delivery Failure Rate\"],\n",
    "            nonoutlier_counts[\"Delivery Failure Rate\"],\n",
    "        ],\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e27cdd-acef-4753-b395-48026fde9803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Delivery Failure Rate': lambda x: count_proportion_outliers(x) * 100,\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delivery Clumpiness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for viz in facet_barplot, facet_boxplot_withfliers, facet_boxplot_nofliers:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=df_snapshot_diffs,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Delivery Clumpiness',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='delivery-clumpiness',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a7b00-69ed-4ad0-a0a9-75c81905f7b4",
   "metadata": {},
   "source": [
    "### Simple Mean and Median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda86c6b-e390-4c28-b5c4-491377986542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/a/13592901\n",
    "df_snapshot_diffs.groupby([\n",
    "    allocation_idx_mapped_title,\n",
    "]).agg({\n",
    "    'Delivery Clumpiness' : [\n",
    "        np.mean,\n",
    "        np.median,\n",
    "    ],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c96c69-348b-457c-86a6-e58bd196f29b",
   "metadata": {},
   "source": [
    "### Median of Replicate Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98644ac1-cd06-4948-96aa-99578d2d9b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_medians = df_snapshot_diffs.groupby([allocation_idx_mapped_title, 'Replicate']).agg({\n",
    "    'Delivery Clumpiness': np.mean\n",
    "}).reset_index()\n",
    "\n",
    "median_of_medians = group_medians.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Delivery Clumpiness': np.mean\n",
    "})\n",
    "\n",
    "baseline = median_of_medians.loc[1, \"Delivery Clumpiness\"].squeeze()\n",
    "median_of_medians[\"normed delta\"] = (median_of_medians[\"Delivery Clumpiness\"] - baseline) / baseline * 100\n",
    "median_of_medians\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17984f4e-ecf7-48b5-94cd-7e8f89d8ec95",
   "metadata": {},
   "source": [
    "### Median of Replicate Medians\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c7941-5073-48c1-b39b-9294fd2a5b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_medians = df_snapshot_diffs.groupby([allocation_idx_mapped_title, 'Replicate']).agg({\n",
    "    'Delivery Clumpiness': np.median\n",
    "}).reset_index()\n",
    "\n",
    "median_of_medians = group_medians.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Delivery Clumpiness': np.median\n",
    "})\n",
    "\n",
    "baseline = median_of_medians.loc[1, \"Delivery Clumpiness\"].squeeze()\n",
    "median_of_medians[\"normed delta\"] = (median_of_medians[\"Delivery Clumpiness\"] - baseline) / baseline * 100\n",
    "median_of_medians\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcd7358-58c9-4029-942c-53688bf9261e",
   "metadata": {},
   "source": [
    "### Median Absolute Deviance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9e496-f089-4fe7-ac34-5fdd383aa74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf = df_snapshot_diffs.copy()\n",
    "xdf['median'] = xdf['Delivery Clumpiness']\n",
    "xdf['median_abs_deviation'] = xdf['Delivery Clumpiness']\n",
    "xdf = xdf.groupby([allocation_idx_mapped_title, 'Replicate']).agg({\n",
    "    'median': np.median,\n",
    "    'median_abs_deviation': stats.median_abs_deviation,\n",
    "}).reset_index()\n",
    "xdf[\"normed median_abs_deviation\"] = xdf[\"median_abs_deviation\"] / xdf[\"median\"] * 100\n",
    "\n",
    "name1, name2 = xdf[allocation_idx_mapped_title].unique()\n",
    "\n",
    "# Extract medians for each group\n",
    "group1 = xdf[xdf[allocation_idx_mapped_title] == name1]['normed median_abs_deviation']\n",
    "group2 = xdf[xdf[allocation_idx_mapped_title] == name2]['normed median_abs_deviation']\n",
    "\n",
    "print(len(group1), len(group2))\n",
    "stats.mannwhitneyu(group1, group2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3bbba1-60bd-4422-a2d9-19c22e9c6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(data=xdf, x=\"normed median_abs_deviation\", hue=allocation_idx_mapped_title)\n",
    "\n",
    "xdf.groupby(allocation_idx_mapped_title)['normed median_abs_deviation'].median().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493085c4-5764-4221-9a79-176965927ac9",
   "metadata": {},
   "source": [
    "### Percent Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ab4d2-ee9c-48a3-b7f3-c36fd6859412",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonoutlier_counts = df_snapshot_diffs.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Delivery Clumpiness': count_nonoutliers,\n",
    "}).reset_index()\n",
    "nonoutlier_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621e3c5-da83-4ee2-9196-07bbb513b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_counts = df_snapshot_diffs.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Delivery Clumpiness': count_outliers,\n",
    "}).reset_index()\n",
    "outlier_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9571015e-40ae-45ca-ad3a-3e2af18d2793",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chi2_contingency(\n",
    "    np.vstack(\n",
    "        [\n",
    "            outlier_counts[\"Delivery Clumpiness\"],\n",
    "            nonoutlier_counts[\"Delivery Clumpiness\"],\n",
    "        ],\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35fa28f-cc60-4c0c-969e-09a89203502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Delivery Clumpiness': lambda x: count_proportion_outliers(x) * 100,\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simstep Period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for viz in facet_barplot, facet_boxplot_withfliers, facet_boxplot_nofliers:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=df_snapshot_diffs,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Simstep Period Inlet (ns)',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='simstep-period-inlet-ns',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e56a70-c0c0-44c3-a1ba-ae587bbcd9c2",
   "metadata": {},
   "source": [
    "### Simple Mean and Median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8416f0f-1577-451a-a2e8-038a6a9ae35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/a/13592901\n",
    "df_snapshot_diffs.groupby([\n",
    "    allocation_idx_mapped_title,\n",
    "]).agg({\n",
    "    'Simstep Period Inlet (ns)' : [\n",
    "        np.mean,\n",
    "        np.median,\n",
    "    ],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc12349-f485-4414-a722-2fb770dddc62",
   "metadata": {},
   "source": [
    "### Median of Replicate Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f4265-ab45-49fc-8257-c952e6f81019",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_medians = df_snapshot_diffs.groupby([allocation_idx_mapped_title, 'Replicate']).agg({\n",
    "    'Simstep Period Inlet (ns)': np.mean\n",
    "}).reset_index()\n",
    "\n",
    "median_of_medians = group_medians.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Simstep Period Inlet (ns)': np.mean\n",
    "})\n",
    "\n",
    "baseline = median_of_medians.loc[1, \"Simstep Period Inlet (ns)\"].squeeze()\n",
    "median_of_medians[\"normed delta\"] = (median_of_medians[\"Simstep Period Inlet (ns)\"] - baseline) / baseline * 100\n",
    "median_of_medians\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e918d7-dcd3-4ec5-9651-ea489683b003",
   "metadata": {},
   "source": [
    "### Median of Replicate Medians\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4527daa-195a-4f50-91f9-2cd224b86ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_medians = df_snapshot_diffs.groupby([allocation_idx_mapped_title, 'Replicate']).agg({\n",
    "    'Simstep Period Inlet (ns)': np.median\n",
    "}).reset_index()\n",
    "\n",
    "median_of_medians = group_medians.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Simstep Period Inlet (ns)': np.median\n",
    "})\n",
    "\n",
    "baseline = median_of_medians.loc[1, \"Simstep Period Inlet (ns)\"].squeeze()\n",
    "median_of_medians[\"normed delta\"] = (median_of_medians[\"Simstep Period Inlet (ns)\"] - baseline) / baseline * 100\n",
    "median_of_medians\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba8ccfb-a27e-40c2-94d0-273fad16b241",
   "metadata": {},
   "source": [
    "### Median Absolute Deviance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099ea495-33f4-44b1-b197-8e5440e4a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf = df_snapshot_diffs.copy()\n",
    "xdf['median'] = xdf['Simstep Period Inlet (ns)']\n",
    "xdf['median_abs_deviation'] = xdf['Simstep Period Inlet (ns)']\n",
    "xdf = xdf.groupby([allocation_idx_mapped_title, 'Replicate']).agg({\n",
    "    'median': np.median,\n",
    "    'median_abs_deviation': stats.median_abs_deviation,\n",
    "}).reset_index()\n",
    "xdf[\"normed median_abs_deviation\"] = xdf[\"median_abs_deviation\"] / xdf[\"median\"] * 100\n",
    "\n",
    "name1, name2 = xdf[allocation_idx_mapped_title].unique()\n",
    "\n",
    "# Extract medians for each group\n",
    "group1 = xdf[xdf[allocation_idx_mapped_title] == name1]['normed median_abs_deviation']\n",
    "group2 = xdf[xdf[allocation_idx_mapped_title] == name2]['normed median_abs_deviation']\n",
    "\n",
    "print(len(group1), len(group2))\n",
    "stats.mannwhitneyu(group1, group2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8a7abf-a5d3-4099-994a-bf90f63c6a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(data=xdf, x=\"normed median_abs_deviation\", hue=allocation_idx_mapped_title)\n",
    "\n",
    "xdf.groupby(allocation_idx_mapped_title)['normed median_abs_deviation'].median().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068a609-4cee-4034-a6fa-a56b79072c0f",
   "metadata": {},
   "source": [
    "### Percent Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6e6ec3-f417-4a85-872b-3786215fb465",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonoutlier_counts = df_snapshot_diffs.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Simstep Period Inlet (ns)': count_nonoutliers,\n",
    "}).reset_index()\n",
    "nonoutlier_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9557f1c-6b18-4e32-a0d8-89413a01d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_counts = df_snapshot_diffs.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Simstep Period Inlet (ns)': count_outliers,\n",
    "}).reset_index()\n",
    "outlier_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378faa89-5487-4b05-a789-7f70ff86c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chi2_contingency(\n",
    "    np.vstack(\n",
    "        [\n",
    "            outlier_counts[\"Simstep Period Inlet (ns)\"],\n",
    "            nonoutlier_counts[\"Simstep Period Inlet (ns)\"],\n",
    "        ],\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b50650-8d7d-4a4b-9d42-fff088abc596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs.groupby(allocation_idx_mapped_title).agg({\n",
    "    'Simstep Period Inlet (ns)': lambda x: count_proportion_outliers(x) * 100,\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for viz in facet_barplot, facet_boxplot_withfliers, facet_boxplot_nofliers:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=df_snapshot_diffs,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Simstep Period Outlet (ns)',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='simstep-period-outlet-ns',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/a/13592901\n",
    "df_snapshot_diffs.groupby([\n",
    "    allocation_idx_mapped_title,\n",
    "]).agg({\n",
    "    'Simstep Period Outlet (ns)' : [\n",
    "        np.mean,\n",
    "        np.median,\n",
    "    ],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_regression_row(*, data, independent_variable, dependent_variable, regression, row_filter):\n",
    "\n",
    "    filtered_data = data[ data.apply(eval(row_filter), axis=1) ]\n",
    "\n",
    "    regfun = {\n",
    "        'Quantile Regression over Means' : smf.quantreg,\n",
    "        'Quantile Regression over Medians' : smf.quantreg,\n",
    "    }[regression]\n",
    "    model = regfun(f\"Q('{dependent_variable}') ~ Q('{independent_variable}')\", filtered_data)\n",
    "    fit_model = model.fit()\n",
    "\n",
    "    slope = fit_model.params[f\"Q('{independent_variable}')\"]\n",
    "    intercept = fit_model.params['Intercept']\n",
    "\n",
    "    slope_ci_lb, slope_ci_ub = fit_model.conf_int().loc[f\"Q('{independent_variable}')\"].tolist()\n",
    "    intercept_ci_lb, intercept_ci_ub = fit_model.conf_int().loc['Intercept'].tolist()\n",
    "\n",
    "    p = fit_model.pvalues.loc[f\"Q('{independent_variable}')\"]\n",
    "\n",
    "    # normalize to \"control\", i.e., lowest num processes observed\n",
    "    effect_size_normalization_data = data[\n",
    "        data[independent_variable] == data[independent_variable].min()\n",
    "    ][dependent_variable]\n",
    "    effect_size_normalization_factor = {\n",
    "        'Quantile Regression over Means' : lambda x: x.mean(),\n",
    "        'Quantile Regression over Medians' : lambda x: x.median(),\n",
    "    }[regression](effect_size_normalization_data)\n",
    "    relative_effect_size = slope / effect_size_normalization_factor\n",
    "    relative_effect_size_ci_lb = slope_ci_lb / effect_size_normalization_factor\n",
    "    relative_effect_size_ci_ub = slope_ci_ub / effect_size_normalization_factor\n",
    "    relative_effect_size_ci_width = (\n",
    "        relative_effect_size_ci_ub\n",
    "        - relative_effect_size_ci_lb\n",
    "    )\n",
    "\n",
    "    is_significant = p < 0.05 if np.isfinite(p) else None\n",
    "\n",
    "    res = {\n",
    "        'Independent Variable' : independent_variable,\n",
    "        'Dependent Variable' : dependent_variable,\n",
    "        'Dependent Variable Slug' : slugify(dependent_variable),\n",
    "        'Cpus Per Node' : ib.dub( data['Cpus Per Node'] ),\n",
    "        'Num Simels Per Cpu' : ip.pophomogeneous( data['Num Simels Per Cpu'] ),\n",
    "        'Slope Estimate' : slope,\n",
    "        'Slope Estimate 95% CI Lower Bound' : slope_ci_lb,\n",
    "        'Slope Estimate 95% CI Upper Bound' : slope_ci_ub,\n",
    "        'Absolute Effect Size' : slope,\n",
    "        'Absolute Effect Size 95% CI Lower Bound' : slope_ci_lb,\n",
    "        'Absolute Effect Size 95% CI Upper Bound' : slope_ci_ub,\n",
    "        'Absolute Effect Size 95% CI Width' : slope_ci_ub - slope_ci_lb,\n",
    "        'Relative Effect Size' : relative_effect_size,\n",
    "        'Relative Effect Size 95% CI Lower Bound' : relative_effect_size_ci_lb,\n",
    "        'Relative Effect Size 95% CI Upper Bound' : relative_effect_size_ci_ub,\n",
    "        'Relative Effect Size 95% CI Width' : relative_effect_size_ci_width,\n",
    "        'Intercept Estimate' : intercept,\n",
    "        'Intercept Estimate 95% CI Lower Bound' : intercept_ci_lb,\n",
    "        'Intercept Estimate 95% CI Upper Bound' : intercept_ci_ub,\n",
    "        'R^2' : fit_model.rsquared,\n",
    "        'p' : fit_model.pvalues.loc[f\"Q('{independent_variable}')\"],\n",
    "        'Significant?' : is_significant,\n",
    "        'Significant Effect Sign' : (\n",
    "            '-' if is_significant and slope < 0\n",
    "            else '+' if is_significant and slope > 0\n",
    "            else '0' if is_significant is not None\n",
    "            else None\n",
    "        ),\n",
    "        'n' : len(filtered_data),\n",
    "        'Filter' : row_filter,\n",
    "        'Num Processes' : ib.dub(filtered_data['Num Processes']),\n",
    "        'Num Processes Prettyprint' : (\n",
    "            '/'.join(filtered_data['Num Processes'].sort_values().astype(str).unique())\n",
    "        ),\n",
    "        'Regression Model' : regression,\n",
    "        'Regression Model Slug' : slugify(regression),\n",
    "        'Statistic' : {\n",
    "            'Quantile Regression over Means' : 'mean',\n",
    "            'Quantile Regression over Medians' : 'median',\n",
    "        }[regression],\n",
    "    }\n",
    "\n",
    "    # dump regression summary to file\n",
    "    summary_filename = kn.pack({\n",
    "        **{\n",
    "            'a' : 'regression_summary',\n",
    "            'ext' : '.txt',\n",
    "        },\n",
    "        **{\n",
    "            slugify(k) : slugify(str(v))\n",
    "            for k, v in res.items()\n",
    "            if k in [\n",
    "                'Independent Variable',\n",
    "                'Dependent Variable',\n",
    "                'Cpus Per Node',\n",
    "                'Num Simels Per Cpu',\n",
    "                'Regression Model',\n",
    "            ]\n",
    "        },\n",
    "    })\n",
    "\n",
    "    pathlib.Path('outplots').mkdir(parents=True, exist_ok=True)\n",
    "    with open(f'outplots/{summary_filename}', 'w') as file:\n",
    "        print(fit_model.summary(), file=file)\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_variables = [\n",
    "    'Latency Walltime Inlet (ns)',\n",
    "    'Latency Walltime Outlet (ns)',\n",
    "    'Latency Simsteps Inlet',\n",
    "    'Latency Simsteps Outlet',\n",
    "    'Delivery Failure Rate',\n",
    "    'Delivery Clumpiness',\n",
    "    'Simstep Period Inlet (ns)',\n",
    "    'Simstep Period Outlet (ns)',\n",
    "]\n",
    "\n",
    "# best-case approximation to replace infs/nans\n",
    "# see listings of infs/nans below\n",
    "df_snapshot_diffs_copy = df_snapshot_diffs.copy()\n",
    "df_snapshot_diffs_copy['Latency Walltime Inlet (ns)'] = (\n",
    "    df_snapshot_diffs_copy['Inlet-Nanoseconds Elapsed']\n",
    "    / np.maximum(df_snapshot_diffs_copy['Num Round Trip Touches Inlet'], 1)\n",
    ")\n",
    "df_snapshot_diffs_copy['Latency Walltime Outlet (ns)'] = (\n",
    "    df_snapshot_diffs_copy['Outlet-Nanoseconds Elapsed']\n",
    "    / np.maximum(df_snapshot_diffs_copy['Num Round Trip Touches Outlet'], 1)\n",
    ")\n",
    "df_snapshot_diffs_copy['Latency Simsteps Inlet'] = (\n",
    "    df_snapshot_diffs_copy['Num Puts Attempted']\n",
    "    / np.maximum(df_snapshot_diffs_copy['Num Round Trip Touches Inlet'], 1)\n",
    ")\n",
    "df_snapshot_diffs_copy['Latency Simsteps Outlet'] = (\n",
    "    df_snapshot_diffs_copy['Num Pulls Attempted']\n",
    "    / np.maximum(df_snapshot_diffs_copy['Num Round Trip Touches Outlet'], 1)\n",
    ")\n",
    "df_snapshot_diffs_copy['Simstep Period Inlet (ns)'] = (\n",
    "    df_snapshot_diffs_copy['Inlet-Nanoseconds Elapsed']\n",
    "    / np.maximum(df_snapshot_diffs_copy['Num Puts Attempted'], 1)\n",
    ")\n",
    "df_snapshot_diffs_copy['Simstep Period Outlet (ns)'] = (\n",
    "    df_snapshot_diffs_copy['Outlet-Nanoseconds Elapsed']\n",
    "    / np.maximum(df_snapshot_diffs_copy['Num Pulls Attempted'], 1)\n",
    ")\n",
    "\n",
    "regression_data_tuples = [\n",
    "    (\n",
    "        'Quantile Regression over Means',\n",
    "        df_snapshot_diffs.groupby([\n",
    "            'Execution Instance UUID',\n",
    "        ]).mean().reset_index().astype({\n",
    "            'Num Processes' : 'int64',\n",
    "            'Allocated Tasks Per Node' : 'int64',\n",
    "            'Cpus Per Node' : 'int64',\n",
    "            'Num Simels Per Cpu' : 'int64',\n",
    "        })\n",
    "    ),\n",
    "    (\n",
    "        'Quantile Regression over Medians',\n",
    "        df_snapshot_diffs.groupby([\n",
    "            'Execution Instance UUID',\n",
    "        ]).median().reset_index().astype({\n",
    "            'Num Processes' : 'int64',\n",
    "            'Allocated Tasks Per Node' : 'int64',\n",
    "            'Cpus Per Node' : 'int64',\n",
    "            'Num Simels Per Cpu' : 'int64',\n",
    "        })\n",
    "    ),\n",
    "]\n",
    "\n",
    "row_filters = [\n",
    "    'lambda row: True',\n",
    "]\n",
    "\n",
    "regression_results = pd.DataFrame.from_records([\n",
    "    make_regression_row(\n",
    "        data=data_subset,\n",
    "        independent_variable=allocation_idx_mapped_title,\n",
    "        dependent_variable=dependent_variable,\n",
    "        regression=regression,\n",
    "        row_filter=row_filter,\n",
    "    )\n",
    "    for row_filter in row_filters\n",
    "    for regression, data in regression_data_tuples\n",
    "    for _, data_subset in data.groupby([\n",
    "        'Num Simels Per Cpu',\n",
    "    ])\n",
    "    for dependent_variable in dependent_variables\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "regression_results[ ~np.isfinite(regression_results['p']) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_attrs = pd.DataFrame.from_records([\n",
    "    {\n",
    "        k : v\n",
    "        for k, v in kn.unpack(source_filename).items()\n",
    "        if k and k[0] != '_' and k != 'ext'\n",
    "    }\n",
    "    for source_filename in [\n",
    "        *df['Source File Inlet'].unique(),\n",
    "        *df['Source File Outlet'].unique(),\n",
    "    ]\n",
    "]).dropna(\n",
    "    axis='columns',\n",
    "    how='any',\n",
    ")\n",
    "\n",
    "out_filename = lambda readability: kn.pack({\n",
    "    **{\n",
    "        col : ib.dub(input_attrs[col])\n",
    "        for col in input_attrs.columns\n",
    "    },\n",
    "    **{\n",
    "        'a' : 'with_lac_417_vs_sans_lac_417_regression_results',\n",
    "        'readability' : readability,\n",
    "        'ext' : '.csv',\n",
    "    },\n",
    "})\n",
    "\n",
    "out_filepath = f\"outplots/{out_filename('human')}\"\n",
    "print(out_filepath)\n",
    "\n",
    "pathlib.Path('outplots').mkdir(parents=True, exist_ok=True)\n",
    "regression_results.to_csv(\n",
    "    out_filepath,\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "out_filepath = f\"outplots/{out_filename('latexcsvreader')}\"\n",
    "print(out_filepath)\n",
    "\n",
    "pathlib.Path('outplots').mkdir(parents=True, exist_ok=True)\n",
    "regression_results.rename(\n",
    "    columns=lambda col: ''.join(filter(str.isalnum, col)),\n",
    ").to_csv(\n",
    "    out_filepath,\n",
    "    index=False,\n",
    "    float_format=lambda col: [\n",
    "        '{:_.0f}'.format(float(f'{x:.2g}')).replace('_', \"'\")\n",
    "         if 10 < abs(x) < 10e5\n",
    "         else f'{x:.2g}' for x in col\n",
    "    ],\n",
    "    na_rep='NaN',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "regression_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/questions/30385975/seaborn-factor-plot-custom-error-bars\n",
    "# and https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html#visualization-errorbars\n",
    "def errplot(x, y, err_lb, err_ub, **kwargs):\n",
    "    ax = plt.gca()\n",
    "    data = kwargs.pop('data')\n",
    "    yerr=np.abs(\n",
    "        data[[err_lb, err_ub]].to_numpy()\n",
    "        - data[[y, y]].to_numpy()\n",
    "    ).transpose()\n",
    "    plt.axhline(\n",
    "        y=0,\n",
    "        zorder=1,\n",
    "        color='black',\n",
    "        linewidth=2,\n",
    "    )\n",
    "    data.plot(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        yerr=yerr,\n",
    "        kind='bar',\n",
    "        ax=ax,\n",
    "        zorder=3,\n",
    "        **kwargs,\n",
    "    ).grid(\n",
    "        axis='y',\n",
    "        zorder=0,\n",
    "    )\n",
    "\n",
    "    if x is None:\n",
    "        # adapted from https://stackoverflow.com/a/12998531\n",
    "        plt.tick_params(\n",
    "            axis='x',          # changes apply to the x-axis\n",
    "            which='both',      # both major and minor ticks are affected\n",
    "            bottom=False,      # ticks along the bottom edge are off\n",
    "            top=False,         # ticks along the top edge are off\n",
    "            labelbottom=False,\n",
    "        )\n",
    "\n",
    "\n",
    "def facet_errplot(*, data, x=None, y, err_lb, err_ub, estimated_statistic, col=None, row=None, size_inches=None, **kwargs):\n",
    "    g = sns.FacetGrid(\n",
    "        subset,\n",
    "        col=col if col is not None and data[col].nunique() > 1 else None,\n",
    "        row=row if row is not None and data[row].nunique() > 1 else None,\n",
    "        margin_titles=True,\n",
    "        sharey=False,\n",
    "    )\n",
    "    g.map_dataframe(\n",
    "        errplot,\n",
    "        x,\n",
    "        y,\n",
    "        err_lb,\n",
    "        err_ub,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    if size_inches is not None:\n",
    "        plt.gcf().set_size_inches(*size_inches)\n",
    "\n",
    "    # adapted from https://stackoverflow.com/a/29814281\n",
    "    plt.gcf().subplots_adjust(top=0.9)\n",
    "    plt.gcf().suptitle(\n",
    "        f\"Estimated Statistic = {estimated_statistic}\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for regression, subset in regression_results.groupby([\n",
    "    'Regression Model',\n",
    "]):\n",
    "    tp.tee(\n",
    "        # prevent filename length error\n",
    "        lambda *args, **kwargs: facet_errplot(\n",
    "            err_lb='Relative Effect Size 95% CI Lower Bound',\n",
    "            err_ub='Relative Effect Size 95% CI Upper Bound',\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        ),\n",
    "        data=subset,\n",
    "\n",
    "        row='Num Simels Per Cpu',\n",
    "        x='Dependent Variable',\n",
    "        y='Relative Effect Size',\n",
    "        estimated_statistic={\n",
    "            'Quantile Regression over Medians' : 'Median',\n",
    "            'Quantile Regression over Means' : 'Mean',\n",
    "        }[regression],\n",
    "        size_inches=(8, 8),\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'fit_regression',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative estimates, alternate\n",
    "\n",
    "for (regression, dependent_variable), subset in regression_results.groupby([\n",
    "    'Regression Model',\n",
    "    'Dependent Variable',\n",
    "]):\n",
    "    tp.tee(\n",
    "        # prevent filename length error\n",
    "        lambda *args, **kwargs: facet_errplot(\n",
    "            err_lb='Relative Effect Size 95% CI Lower Bound',\n",
    "            err_ub='Relative Effect Size 95% CI Upper Bound',\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        ),\n",
    "        data=subset,\n",
    "\n",
    "        row='Num Simels Per Cpu',\n",
    "        y='Relative Effect Size',\n",
    "        estimated_statistic={\n",
    "            'Quantile Regression over Medians' : f'{dependent_variable} Median',\n",
    "            'Quantile Regression over Means' : f'{dependent_variable} Mean',\n",
    "        }[regression],\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'fit_regression',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir=slugify(dependent_variable),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute estimates\n",
    "\n",
    "for (regression, dependent_variable), subset in regression_results.groupby([\n",
    "    'Regression Model',\n",
    "    'Dependent Variable',\n",
    "]):\n",
    "    tp.tee(\n",
    "        # prevent filename length error\n",
    "        lambda *args, **kwargs: facet_errplot(\n",
    "            err_lb='Absolute Effect Size 95% CI Lower Bound',\n",
    "            err_ub='Absolute Effect Size 95% CI Upper Bound',\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        ),\n",
    "        data=subset,\n",
    "\n",
    "        row='Num Simels Per Cpu',\n",
    "        y='Absolute Effect Size',\n",
    "        estimated_statistic={\n",
    "            'Quantile Regression over Medians' : f'{dependent_variable} Median',\n",
    "            'Quantile Regression over Means' : f'{dependent_variable} Mean',\n",
    "        }[regression],\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'fit_regression',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir=slugify(dependent_variable),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_regplot(fit_reg=True, color=None, *args, **kwargs):\n",
    "    x, y, data = kwargs['x'], kwargs['y'], kwargs['data']\n",
    "    sns.regplot(\n",
    "        *args,\n",
    "        **kwargs,\n",
    "        fit_reg=False,\n",
    "        color=color,\n",
    "    )\n",
    "\n",
    "    if fit_reg:\n",
    "        model = smf.quantreg(\n",
    "            f\"Q('{y}') ~ Q('{x}')\",\n",
    "            data\n",
    "        )\n",
    "        res = model.fit(q=0.5)\n",
    "        m = res.params[f\"Q('{x}')\"]\n",
    "        b = res.params['Intercept']\n",
    "\n",
    "        m_ci = res.conf_int().loc[f\"Q('{x}')\"].tolist()\n",
    "        b_ci = res.conf_int().loc['Intercept'].tolist()\n",
    "\n",
    "        center_x = np.mean([data[x].min(), data[x].max()])\n",
    "        center_y = m * center_x + b\n",
    "\n",
    "        xs = sorted(set(data[x]) | {center_x})\n",
    "        ys = [\n",
    "            m * x_ + b\n",
    "            for x_ in xs\n",
    "        ]\n",
    "        y1 = [ min(\n",
    "                m_ * ( x_ - center_x ) + center_y\n",
    "                for m_ in m_ci\n",
    "        ) for x_ in xs ]\n",
    "        y2 = [ max(\n",
    "                m_ * ( x_ - center_x ) + center_y\n",
    "                for m_ in m_ci\n",
    "        ) for x_ in xs ]\n",
    "\n",
    "        plt.gca().plot(\n",
    "            xs,\n",
    "            ys,\n",
    "            color=color,\n",
    "        )\n",
    "        plt.gca().fill_between(\n",
    "            xs,\n",
    "            y1,\n",
    "            y2,\n",
    "            alpha=0.2,\n",
    "            color=color,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsplit_regression(*args, regplot, **kwargs):\n",
    "    del kwargs['color']\n",
    "    regplot(\n",
    "        *args,\n",
    "        **kwargs,\n",
    "        color='black',\n",
    "        fit_reg=False,\n",
    "    )\n",
    "    regplot(\n",
    "        *args,\n",
    "        **kwargs,\n",
    "        color='purple',\n",
    "        scatter=False,\n",
    "    )\n",
    "\n",
    "    # adapted from https://www.scivision.dev/matplotlib-force-integer-labeling-of-axis/\n",
    "    plt.gca().xaxis.set_major_locator(\n",
    "        matplotlib.ticker.MaxNLocator(\n",
    "            integer=True,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "def facet_unsplit_regression(*, data, col=None, row=None, x, y, regression, **kwargs):\n",
    "    g = sns.FacetGrid(\n",
    "        data,\n",
    "        col=col if col is not None and data[col].nunique() > 1 else None,\n",
    "        row=row if row is not None and data[row].nunique() > 1 else None,\n",
    "        margin_titles=True,\n",
    "        sharey=False,\n",
    "    )\n",
    "    g.map_dataframe(\n",
    "        unsplit_regression,\n",
    "        regplot={\n",
    "            'Ordinary Least Squares Regression' : quantile_regplot,\n",
    "            'Quantile Regression' : quantile_regplot,\n",
    "        }[regression],\n",
    "        x=x,\n",
    "        y=y,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    # adapted from https://stackoverflow.com/a/48208266\n",
    "    g.set_axis_labels(x_var=x, y_var=y)\n",
    "\n",
    "    # adapted from https://stackoverflow.com/a/29814281\n",
    "    plt.gcf().subplots_adjust(top=0.8)\n",
    "    plt.gcf().suptitle(\n",
    "        {\n",
    "            \"Quantile Regression\": \"Quantile Regression over Medians\",\n",
    "            \"Ordinary Least Squares Regression\": \"Quantile Regression over Means\",\n",
    "        }[regression],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency Walltime Inlet (ns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs[\n",
    "    ~np.isfinite(df_snapshot_diffs['Latency Walltime Inlet (ns)'])\n",
    "][[\n",
    "    'Latency Walltime Inlet (ns)',\n",
    "    'Latency Walltime Outlet (ns)',\n",
    "    'Snapshot',\n",
    "    'Runtime Seconds Elapsed Outlet',\n",
    "    'Hostname',\n",
    "    'Replicate',\n",
    "    'Num Simels Per Cpu',\n",
    "    'Cpus Per Node',\n",
    "    'Num Processes',\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs_copy = df_snapshot_diffs.copy()\n",
    "\n",
    "# best-case approximation to replace infs/nans\n",
    "# see listing of infs/nans above\n",
    "df_snapshot_diffs_copy['Latency Walltime Inlet (ns)'] = (\n",
    "    df_snapshot_diffs_copy['Inlet-Nanoseconds Elapsed']\n",
    "    / np.maximum(df_snapshot_diffs_copy['Num Round Trip Touches Inlet'], 1)\n",
    ")\n",
    "\n",
    "data = df_snapshot_diffs_copy.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).mean().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "})\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Latency Walltime Inlet (ns)',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Ordinary Least Squares Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-mean',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='latency-walltime-inlet-ns',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_snapshot_diffs.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).median().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "})\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Latency Walltime Inlet (ns)',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Quantile Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-median',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='latency-walltime-inlet-ns',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency Walltime Outlet (ns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs[\n",
    "    ~np.isfinite(df_snapshot_diffs['Latency Walltime Outlet (ns)'])\n",
    "][[\n",
    "    'Latency Walltime Inlet (ns)',\n",
    "    'Latency Walltime Outlet (ns)',\n",
    "    'Snapshot',\n",
    "    'Runtime Seconds Elapsed Outlet',\n",
    "    'Hostname',\n",
    "    'Replicate',\n",
    "    'Num Simels Per Cpu',\n",
    "    'Cpus Per Node',\n",
    "    'Num Processes',\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs_copy = df_snapshot_diffs.copy()\n",
    "\n",
    "# best-case approximation to replace infs/nans\n",
    "# see listing of infs/nans above\n",
    "df_snapshot_diffs_copy['Latency Walltime Outlet (ns)'] = (\n",
    "    df_snapshot_diffs_copy['Outlet-Nanoseconds Elapsed']\n",
    "    / np.maximum(df_snapshot_diffs_copy['Num Round Trip Touches Outlet'], 1)\n",
    ")\n",
    "\n",
    "data = df_snapshot_diffs_copy.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).mean().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "})\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Latency Walltime Outlet (ns)',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Ordinary Least Squares Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-mean',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='latency-walltime-outlet-ns',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_snapshot_diffs.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).median().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "})\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Latency Walltime Outlet (ns)',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Quantile Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-median',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='latency-walltime-outlet-ns',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency Simsteps Inlet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs[\n",
    "    ~np.isfinite(df_snapshot_diffs['Latency Simsteps Inlet'])\n",
    "][[\n",
    "    'Latency Simsteps Inlet',\n",
    "    'Latency Simsteps Outlet',\n",
    "    'Snapshot',\n",
    "    'Runtime Seconds Elapsed Outlet',\n",
    "    'Hostname',\n",
    "    'Replicate',\n",
    "    'Num Simels Per Cpu',\n",
    "    'Cpus Per Node',\n",
    "    'Num Processes',\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs_copy = df_snapshot_diffs.copy()\n",
    "\n",
    "# best-case approximation to replace infs/nans\n",
    "# see listing of infs/nans above\n",
    "df_snapshot_diffs_copy['Latency Simsteps Inlet'] = (\n",
    "    df_snapshot_diffs_copy['Num Puts Attempted']\n",
    "    / np.maximum(df_snapshot_diffs_copy['Num Round Trip Touches Inlet'], 1)\n",
    ")\n",
    "\n",
    "data = df_snapshot_diffs_copy.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).mean().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "})\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Latency Simsteps Inlet',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Ordinary Least Squares Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-mean',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='latency-simsteps-inlet',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_snapshot_diffs.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).median().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "})\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Latency Simsteps Inlet',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Quantile Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-median',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='latency-simsteps-inlet',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency Simsteps Outlet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs[\n",
    "    ~np.isfinite(df_snapshot_diffs['Latency Simsteps Outlet'])\n",
    "][[\n",
    "    'Latency Simsteps Inlet',\n",
    "    'Latency Simsteps Outlet',\n",
    "    'Snapshot',\n",
    "    'Runtime Seconds Elapsed Outlet',\n",
    "    'Hostname',\n",
    "    'Replicate',\n",
    "    'Num Simels Per Cpu',\n",
    "    'Cpus Per Node',\n",
    "    'Num Processes',\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs_copy = df_snapshot_diffs.copy()\n",
    "\n",
    "# best-case approximation to replace infs/nans\n",
    "# see listing of infs/nans above\n",
    "df_snapshot_diffs_copy['Latency Simsteps Outlet'] = (\n",
    "    df_snapshot_diffs_copy['Num Pulls Attempted']\n",
    "    / np.maximum(df_snapshot_diffs_copy['Num Round Trip Touches Outlet'], 1)\n",
    ")\n",
    "\n",
    "data = df_snapshot_diffs_copy.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).mean().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "})\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Latency Simsteps Outlet',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Ordinary Least Squares Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-mean',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='latency-simsteps-outlet',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_snapshot_diffs.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).median().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "})\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Latency Simsteps Outlet',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Quantile Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-median',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='latency-simsteps-outlet',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delivery Failure Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs[\n",
    "    ~np.isfinite(df_snapshot_diffs['Delivery Failure Rate'])\n",
    "][[\n",
    "    'Delivery Failure Rate',\n",
    "    'Snapshot',\n",
    "    'Runtime Seconds Elapsed Outlet',\n",
    "    'Hostname',\n",
    "    'Replicate',\n",
    "    'Num Simels Per Cpu',\n",
    "    'Cpus Per Node',\n",
    "    'Num Processes',\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_snapshot_diffs.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).mean().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "})\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Delivery Failure Rate',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Ordinary Least Squares Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-mean',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='delivery-failure-rate',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_snapshot_diffs.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).median().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "})\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Delivery Failure Rate',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Quantile Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-median',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='delivery-failure-rate',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delivery Clumpiness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs[\n",
    "    ~np.isfinite(df_snapshot_diffs['Delivery Clumpiness'])\n",
    "][[\n",
    "    'Delivery Clumpiness',\n",
    "    'Snapshot',\n",
    "    'Runtime Seconds Elapsed Outlet',\n",
    "    'Hostname',\n",
    "    'Replicate',\n",
    "    'Num Simels Per Cpu',\n",
    "    'Cpus Per Node',\n",
    "    'Num Processes',\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_snapshot_diffs.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).mean().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "})\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Delivery Clumpiness',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Ordinary Least Squares Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-mean',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='delivery-clumpiness',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_snapshot_diffs.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).median().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "})\n",
    "\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Delivery Clumpiness',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Quantile Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-median',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='delivery-clumpiness',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simstep Period Inlet (ns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs[\n",
    "    ~np.isfinite(df_snapshot_diffs['Simstep Period Inlet (ns)'])\n",
    "][[\n",
    "    'Simstep Period Inlet (ns)',\n",
    "    'Simstep Period Outlet (ns)',\n",
    "    'Snapshot',\n",
    "    'Runtime Seconds Elapsed Outlet',\n",
    "    'Hostname',\n",
    "    'Replicate',\n",
    "    'Num Simels Per Cpu',\n",
    "    'Cpus Per Node',\n",
    "    'Num Processes',\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs_copy = df_snapshot_diffs.copy()\n",
    "\n",
    "# best-case approximation to replace infs\n",
    "# see listing of infs above\n",
    "df_snapshot_diffs_copy['Simstep Period Inlet (ns)'] = (\n",
    "    df_snapshot_diffs_copy['Inlet-Nanoseconds Elapsed']\n",
    "    / np.maximum(df_snapshot_diffs_copy['Num Puts Attempted'], 1)\n",
    ")\n",
    "\n",
    "data = df_snapshot_diffs_copy.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).mean().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "})\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Simstep Period Inlet (ns)',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Ordinary Least Squares Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-mean',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='simstep-period-inlet-ns',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_snapshot_diffs.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).median().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "})\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Simstep Period Inlet (ns)',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Quantile Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-median',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='simstep-period-inlet-ns',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simstep Period Outlet (ns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs[\n",
    "    ~np.isfinite(df_snapshot_diffs['Simstep Period Outlet (ns)'])\n",
    "][[\n",
    "    'Simstep Period Inlet (ns)',\n",
    "    'Simstep Period Outlet (ns)',\n",
    "    'Snapshot',\n",
    "    'Runtime Seconds Elapsed Outlet',\n",
    "    'Hostname',\n",
    "    'Replicate',\n",
    "    'Num Simels Per Cpu',\n",
    "    'Cpus Per Node',\n",
    "    'Num Processes',\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs_copy = df_snapshot_diffs.copy()\n",
    "\n",
    "# best-case approximation to replace infs\n",
    "# see listing of infs above\n",
    "df_snapshot_diffs_copy['Simstep Period Outlet (ns)'] = (\n",
    "    df_snapshot_diffs_copy['Outlet-Nanoseconds Elapsed']\n",
    "    / np.maximum(df_snapshot_diffs_copy['Num Pulls Attempted'], 1)\n",
    ")\n",
    "\n",
    "data = df_snapshot_diffs_copy.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).mean().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "})\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Simstep Period Outlet (ns)',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Ordinary Least Squares Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-mean',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='simstep-period-outlet-ns',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_snapshot_diffs.groupby([\n",
    "    'Execution Instance UUID',\n",
    "]).median().reset_index().astype({\n",
    "    'Num Processes' : 'int64',\n",
    "    'Allocated Tasks Per Node' : 'int64',\n",
    "    'Cpus Per Node' : 'int64',\n",
    "    'Num Simels Per Cpu' : 'int64',\n",
    "    allocation_idx_mapped_title : 'int64',\n",
    "})\n",
    "\n",
    "for viz in facet_unsplit_regression,:\n",
    "    tp.tee(\n",
    "        viz,\n",
    "        data=data,\n",
    "        row='Num Simels Per Cpu',\n",
    "        x=allocation_idx_mapped_title,\n",
    "        y='Simstep Period Outlet (ns)',\n",
    "        marker='+',\n",
    "        x_jitter=0.15,\n",
    "        regression='Quantile Regression',\n",
    "        teeplot_outattrs={\n",
    "            **{\n",
    "                'transform' : 'snapshot_diffs-groupby_exec_instance-median',\n",
    "            },\n",
    "            **nbm.collate_outattr_metadata(),\n",
    "        },\n",
    "        teeplot_subdir='simstep-period-outlet-ns',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "df_snapshot_diffs[\n",
    "    (df_snapshot_diffs['Latency Simsteps Inlet'] > 50)\n",
    "    & (df_snapshot_diffs['Num Simels Per Cpu'] == 1)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "df_snapshot_diffs[\n",
    "    (df_snapshot_diffs['Latency Simsteps Inlet'] > 50)\n",
    "    & (df_snapshot_diffs['Num Simels Per Cpu'] == 2048)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshot_diffs[\"Num Messages Per Pull\"] = (\n",
    "    df_snapshot_diffs['Net Flux Through Duct']\n",
    "    / df_snapshot_diffs['Num Pulls That Were Laden Immediately']\n",
    "    / df_snapshot_diffs[\"Delivery Success Rate\"]\n",
    ").clip(lower=1)\n",
    "assert (df_snapshot_diffs[\"Num Messages Per Pull\"] >= 1).all()\n",
    "df_snapshot_diffs[\"Any Messages Dropped\"] = df_snapshot_diffs[\"Fraction Messages Dropped\"].astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_semantics_plot(\n",
    "    data=df_snapshot_diffs,\n",
    "    hue=\"Allocation\",\n",
    "    hue_order=[\"Sans lac-417\", \"With lac-417\"],\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
